---
title: 'Homework #6'
output: html_document
---

---
title: "LDA, QDA"
author: "Tomasz Zaremba"
date: "19.11.2015"
output: 
  html_document:
    toc: TRUE

## The Homework

Use the k-fold cross validation to assess the performance of lda/qda on the wines dataset.

```{r}
wines <- read.table("http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv",sep=";", header=TRUE)
wines$quality <- factor(ifelse(wines$quality > 5, "good", "bad")) 
```

## LDA
```{r}
library(caret)
train_control <- trainControl(method="cv", number=10)
lda<- train(quality~., method='lda',preProcess=c('scale', 'center'), data=wines, trControl=train_control)
pred <- predict(lda, wines)
confusionMatrix <- confusionMatrix(wines$quality, pred)$overall
round(confusionMatrix*100,2)
```

## QDA
```{r}
qda<- train(quality~.,   method='qda', preProcess=c('scale', 'center'), data=wines, trControl=train_control)
pred <- predict(qda, wines)
confusionMatrix <- confusionMatrix(wines$quality, pred)$overall
round(confusionMatrix*100,2)
```

## Conclusions
LDA is a special case of QDA and in our example both approaches yield very similar results. They are not very good though, probably because the classes are not easy to separate with straight or quadratic lines.
