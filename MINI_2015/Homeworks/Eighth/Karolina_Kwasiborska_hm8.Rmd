---
title: "Homework #8"
author: "Karolina Kwasiborska"
date: "02-12-2015"
output: 
  html_document:
  toc : TRUE
---

  
# Homework
Compare performance of random forests from projects of three groups and check why it differse.

## Data Loading
```{r , cache=TRUE, warning=FALSE, message=FALSE}

library(caret)
library(randomForest)

australianDataSet = read.table("C:\\Users\\Karola\\Documents\\BISD\\Semestr 2\\Data Mining\\Projekt 1\\australian.dat",
                               sep=" ",header=F,col.names=c("A1", "A2", "A3", "A4", 
                                                            "A5","A6", "A7", "A8", "A9","A10",
                                                            "A11", "A12", "A13","A14", "A15"),
                               fill=FALSE,strip.white=T)

```

# First group solution
```{r , cache=TRUE, warning=FALSE, message=FALSE}

australianDataSet$A15 <- factor(ifelse(australianDataSet$A15 == 0, "One", "Zero"))

# Partitioning
indxTrain <- createDataPartition(y = australianDataSet$A15, p = 0.8)
australianDataSetTrain<- australianDataSet[indxTrain$Resample1,]
australianDataSetTest <- australianDataSet[-indxTrain$Resample1,]

# Classifiers Training And Testing
model<- train(A15 ~ A8 + A14 + A10 + A5 +A7 + A13 + A9, data=australianDataSetTrain, method="rf")

# Accuracy
predTab <- predict(model, australianDataSetTest)
round(confusionMatrix(predTab, australianDataSetTest$A15)$overall*100,2)

```

## Modification
```{r , cache=TRUE, warning=FALSE, message=FALSE}
# Classifiers Training And Testing
# Random forest with all variables
train_control <- trainControl(method="cv", number=10)
model<- train(A15 ~ A8 + A14 + A10 + A5 +A7 + A13 + A9, data=australianDataSet, method="rf", trControl=train_control)

# Accuracy
predTab <- predict(model, australianDataSet)
round(confusionMatrix(predTab, australianDataSet$A15)$overall*100,2)

```

# Second group solution
```{r , cache=TRUE, warning=FALSE, message=FALSE}
# Dividing dataset into training and testing set
set.seed(1313)
indxTrain <- createDataPartition(y = australianDataSet$A15, p = 0.75)
str(indxTrain)

australianTrain <- australianDataSet[indxTrain$Resample1,]
australianTest <- australianDataSet[-indxTrain$Resample1,]

# Random forest with all variables
model<- train(A15~., method="rf", data=australianTrain)
round(confusionMatrix(australianTest$A15, predict(model, australianTest))$overall*100,2)

# Random forest with 3 most important variables
model<- train(A15~A8+A10+A7, method='rf', data=australianTrain)
round(confusionMatrix(australianTest$A15, predict(model, australianTest))$overall*100,2)

```

## Modification
```{r , cache=TRUE, warning=FALSE, message=FALSE}
# Random forest with 3 most important variables
train_control <- trainControl(method="cv", number=10)
model<- train(A15~A8+A10+A7, method='rf', data=australianDataSet, trControl=train_control)
round(confusionMatrix(australianDataSet$A15, predict(model, australianDataSet))$overall*100,2)

```

# Third group solution
```{r, cache=TRUE, warning=FALSE, message=FALSE}
# Random forest with all variables
train_control <- trainControl(method="cv", number=10)
model <- train(A15 ~ ., method="rf", data=australianDataSet, trControl=train_control, preProcess=c('scale', 'center'))
round(confusionMatrix(australianDataSet$A15, predict(model, australianDataSet))$overall*100,2)

# Random forest with chosen variables
model <- train(A15 ~ A8 + A7 + A10 + A14 + A3, method="rf", data=australianDataSet, trControl=train_control, preProcess=c('scale', 'center'))
round(confusionMatrix(australianDataSet$A15, predict(model, australianDataSet))$overall*100,2)
```

## Modification
```{r, cache=TRUE, warning=FALSE, message=FALSE}
# Partitioning
indxTrain <- createDataPartition(y = australianDataSet$A15, p = 0.8)
australianDataSetTrain<- australianDataSet[indxTrain$Resample1,]
australianDataSetTest <- australianDataSet[-indxTrain$Resample1,]

# Random forest with all variables
model <- train(A15 ~ ., method="rf", data=australianDataSetTrain, preProcess=c('scale', 'center'))
round(confusionMatrix(australianDataSetTest$A15, predict(model, australianDataSetTest))$overall*100,2)

# Random forest with chosen variables
model <- train(A15 ~ A8 + A7 + A10 + A14 + A3, method="rf", data=australianDataSetTrain, preProcess=c('scale', 'center'))
round(confusionMatrix(australianDataSetTest$A15, predict(model, australianDataSetTest))$overall*100,2)
```

## Summary
The two most important differences in the solutions of all groups are:
<br>- The use of training and testing sets or k-fold cross-validation
<br>- Creation of a model using different variables

It is easy to notice that the use of cross-validation method significantly improves the results. The third group gained thus approx. 10% better performance. Replacing these methods in "Modification" blocks in the first group code (for cross-validation) and third group code (for training and testing set) confirms this statement.

Another factor which affectes the performances are variables. We can observe that, when the only difference between all approaches are chosen variables. A model with only three features (A15 ~ A8 + A10 + A7) is the worst one, whereas models with greater number of variables are much better.