---
title: "Homework 3"
author: "Marcel Sz"
date: "22 paüdziernika 2015"
output: html_document
---

# Homework 3
## Homework description 

Download the dataset adult (find more about this dataset here: http://archive.ics.uci.edu/ml/machine-learning-databases/adult/). Train a decision tree and a random forest. Compare performance of both methods.

##Loading libraries and data


```{r}
library(faraway)
library(MASS)
library(ggplot2)
adult = read.table("http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data",
sep=",",header=F,col.names=c("age", "type_employer", "fnlwgt", "education", "education_num","marital", "occupation", "relationship", "race","sex", "capital_gain", "capital_loss", "hr_per_week","country", "income"),
        fill=FALSE,strip.white=T)
head(data,3)
```

##Decision tree
```{r}
library(rpart)
rtree <- rpart(sex ~ marital+education, data = adult, method="class")
rtree
par(mar=c(1,1,1,1))
plot(rtree)
text(rtree)
```


```{r}
rtree <- rpart(sex ~ marital+education, data = adult,
    parms=list(split = "information"), method="class")
plot(rtree)
text(rtree)

rtree <- rpart(sex ~ marital+education, data = adult,
    parms=list(split = "gini"), method="class")
plot(rtree)
text(rtree)

tfit <- rpart(sex ~ marital+education, data = adult,
    parms=list(split = "gini"),
    control = rpart.control(cp = 0,minsplit = 10,minbucket =5))
tfit

plot(tfit)
text(tfit)
```

##Deeper examination of a tree
```{r}
par(mar=c(2,2,2,1))
plotcp(tfit)
```

```{r}
printcp(tfit)
```

```{r}
tfit <- rpart(sex ~ marital+education, data = adult,
    parms=list(split = "gini"),
    control = rpart.control(cp=0))

summary(tfit)
```

##Modifying the tree display manner

```{r}
plot(tfit, uniform=TRUE)
text(tfit, use.n=TRUE, all=TRUE, cex=.8)
```

```{r}
prune(tfit, cp=0.02)
```
#Cpart
Using cpart because for better tree visualization

```{r}
library(party)
diabTree <- ctree(sex ~ marital+education, data = adult)

diabTree

plot(diabTree)

table(real = adult$sex,
      predicted = predict(diabTree))
```

##Specifing additional parameters (mincriterion, minsplit, minbucket)
```{r}
diabTree <- ctree(sex ~ marital+education, data = adult,
                    controls = ctree_control(mincriterion=0.1, minsplit=100, minbucket = 5000))
diabTree
plot(diabTree)
```

#Random Forest
```{r}
library(randomForest)
ffit <- randomForest(sex ~ marital+education, data = adult, importance = TRUE)
print(ffit)
```

#Importance scores for variables.
```{r}
importance(ffit)
```

#Importance plot for variables.

```{r,}
varImpPlot(ffit)
```

#ROC Curves

Drawing ROC curves to assess performance.
```{r}
prob <- predict(ffit, type="prob")[,2]
library(ROCR)
fit.pred = prediction(prob, adult$sex)
fit.perf = performance(fit.pred,"tpr","fpr")
par(mar = c(3,3,3,3))
plot(fit.perf)
abline(a=0,b=1)
```
