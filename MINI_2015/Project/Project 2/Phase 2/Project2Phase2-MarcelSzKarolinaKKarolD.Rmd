---
title: "Project 2 - Phase 2"
author: "Karolina K., Karol D., Marcel Sz."
date: "7 stycznia 2016"
output: html_document
---
#Project Phase Description

In the second phase try to segment visitors into separate categories / segments. Try to answer following questions:
<ul>
<li>
How to define the similarity measure between visitors?
<li>
Is the population homogenous or heterogonous. If heterogeneous then how many groups you can derive/define?
<li>
How to characterize different groups of visitors?
Is there a pattern in stations that visitor tends to visit?

#Loading libraries
```{r, warning=FALSE, results="hide"}
library(tidyr)
library(caret)
library(dplyr)
library(lubridate)
library(reshape)
library(ggplot2)
library(MASS)
library(cluster)
library(pvclust)
library(dendextend)
library(ape)
library(RColorBrewer)
library(scales)
library(colorspace) # get nice colors
library(plotly)
library(stringdist)
```

# Loading data
```{r, cache=TRUE}
load("verySmallLogs.rda")
```
```{r, cache=TRUE}
#Transforming data in the same way as in phase 1

data <- verySmallLogs %>% 
  mutate(station,
         visitor,
         type,
         date,
         weekday = wday(date, label=TRUE, abbr=FALSE),
         hour = substr(date, 12, 13))

data$date <- as.POSIXct(data$date,format="%Y-%m-%d %H:%M:%S")
data = data[data$visitor != -1,]


dataEntering <- data[data$type=="Entering" & data$visitor != -1,]
dataLeaving <- data[data$type=="Leaving" & data$visitor != -1,]

newdataEntering = dataEntering %>%
  group_by(visitor, station) %>%
  summarise(min_date=min(date),
            weekday=head(weekday,1),
            hour=head(hour,1),
            count = n())

newdataLeaving = dataLeaving %>%
  group_by(visitor, station) %>%
  summarise(max_date=max(date),
            weekday=head(weekday,1),
            hour=head(hour,1),
            count = n())

mergedData <- merge(newdataEntering, newdataLeaving, by=c("visitor", "station"))
mergedData$time = as.numeric(mergedData$max_date-mergedData$min_date)
mergedData$hour = mergedData$hour.x
mergedData$weekday = mergedData$weekday.x
mergedData$count = mergedData$count.x
mergedData = mergedData[mergedData$time < 1000,]
```

#Introduce new features
Try to get data by visitor (not by visitor, station) and introduce new features that we tried to use in our clustering

<ol><li>Time dependent features
   <ul><li> total_time - total time spent by visitor on all stations </li>
   <li> max_time - maximal time spent by visitor on one station </li>
   <li> min_time - minimal time spent by visitor on one station </li>
   <li> weekday - a day of a week</li>
   <li> hour - an hour user started using stations </li>
   <li> min_date - an hour with minutes as numeric type of entering first station by visitor </li>
   <li> max_date - an hour with minutes as numeric type of leaving last station by visitor </li> 
   </ul></li>
 <li>station dependent features </li>
 <ul>
   <li> most_freq_station - a station with most interactions with that visitor </li>
   <li> least_freq_station - a station with least interactions with that visitor </li>
   <li> min_count - a minimal number of iteration with a station </li>
   <li> max_count - a maximal number of iteration with a station </li>
   <li> total_count - a total number of iterations with all stations made by the visitor </li>
</ul>
</li>
</ol>

As a distance metric we will use deafault distance between vectors used by kmeans, of selected features from those above.
To cluster our data in this part we will use kmeans algorithm.

```{r, cache=TRUE}
phase1Data <- mergedData[,c("visitor", "station", "max_date", "min_date", "time", "weekday", "hour", "count")]

phase1Data = phase1Data %>%
  group_by(visitor) %>%
  summarise(max_date=max(max_date),
            min_date=min(min_date),
            total_time=sum(time),
            min_time=min(time),
            max_time=max(time),
            weekday=head(weekday,1),
            hour=head(hour,1),
            total_count = sum(count),
            max_count = max(count),
            min_count = min(count),
            most_freq_station = head(station[which(count == max(count))],1),
            least_freq_station = head(station[which(count == min(count))],1))

sampleData <- phase1Data[sample(nrow(phase1Data), 20000),]
sampleData <- sampleData[order(sampleData$visitor),]
rownames(sampleData) <- sampleData$visitor
```

## Scaling data and transforming to numeric

```{r, cache=TRUE}

kmeansData <- transform(sampleData, 
                        visitor = as.numeric(visitor),
                        max_date = as.POSIXlt(max_date)$hour + as.POSIXlt(max_date)$min/60,
                        min_date = as.POSIXlt(min_date)$hour + as.POSIXlt(min_date)$min/60,
                        total_time = as.numeric(total_time),
                        min_time = as.numeric(min_time),
                        max_time = as.numeric(max_time),
                        hour = as.numeric(hour),
                        label = visitor)
```

```{r, cache=TRUE}
 kmeansData$max_date <- scale(kmeansData$max_date)
 kmeansData$min_date <- scale(kmeansData$min_date)
 kmeansData$total_time <- scale(kmeansData$total_time)
 kmeansData$min_time <- scale(kmeansData$min_time)
 kmeansData$max_time <- scale(kmeansData$max_time)
 kmeansData$total_count <- scale(kmeansData$total_count)
 kmeansData$max_count <- scale(kmeansData$max_count)
 kmeansData$min_count <- scale(kmeansData$min_count)
```

##Trying to visualize data

Plot a SPLOM: (how features depend of each other)

```{r, cache=TRUE, results="hide", warning=FALSE, message=FALSE, fig.width=15,  fig.height=15,}
SPLOM_DATA <- kmeansData[,c("total_time", "max_time", "min_time","min_date", "max_date", "min_count", "max_count", "total_count")]
station_col <- rev(rainbow_hcl(65))[as.numeric(sampleData$most_freq_station)]
pairs(SPLOM_DATA, col = station_col,
      lower.panel = NULL,
      cex.labels=1, pch=15, cex = 0.75)
```

## Get most important features based on PCA

We can see that most variance is introduced by total_count and min_data or total_time variables. 
So we will try to cluster our data using them as main features. We also will visualize our data mostly using total_count and total_time.

```{r, cache=TRUE, fig.width=15,  fig.height=15}
pc <- prcomp(SPLOM_DATA)
biplot(pc, xlabs=rep("Â·", nrow(SPLOM_DATA)))
 
```


##Use K-means on features: total_time, min_date, max_date, total_count

Low min_date or max_date means that these are users playing mostly in morning ours, 
while higher values indicates user playing more on evening hours. We will later try to gather more
detailed info about visitors in that classes.

```{r}
set.seed(4)
model1 <- kmeans(kmeansData[,c("total_time", "max_date", "min_date", "total_count")], 3)
kmeansData$cluster <- factor(model1$cluster)
nd <- data.frame(model1$centers)

ggplot(kmeansData, aes(total_time, total_count)) +
  geom_text(size=3, aes(label=most_freq_station, color=cluster)) + 
  geom_point(data=nd, size=3)+
  theme_bw()

ggplot(kmeansData, aes(total_time, max_date)) +
  geom_text(size=3, aes(label=most_freq_station, color=cluster)) + 
  geom_point(data=nd, size=3)+
  theme_bw()

ggplot(kmeansData, aes(total_time, min_date)) +
  geom_text(size=3, aes(label=most_freq_station, color=cluster)) + 
  geom_point(data=nd, size=3)+
  theme_bw()

```

##Use K-means on features: total_time, total_count

Firstly we tried to analyse visitors clustered by total_time and total_count features, splitting them to
groups of visitors how play long and do many iterations and those to play shorter and do less interactions.
In order to do that we cluster in 4 groups and analyze what stations people in every group mostly use.

```{r}
set.seed(4)
model1 <- kmeans(kmeansData[,c("total_time", "total_count")], 4)
kmeansData$cluster <- factor(model1$cluster)
nd <- data.frame(model1$centers)

ggplot(kmeansData, aes(total_time, total_count)) +
  geom_text(size=3, aes(label=most_freq_station, color=cluster)) + 
  geom_point(data=nd, size=3)+
  theme_bw()

kmFirstGroup = kmeansData[kmeansData$cluster == 1,]
kmSecondGroup = kmeansData[kmeansData$cluster == 2,]
kmThirdGroup = kmeansData[kmeansData$cluster == 3,]
kmFourthGroup = kmeansData[kmeansData$cluster == 4,]
```

### Most frequent station

Analysis of most_frequent station with data clustered in 4 groups, we can see here that usage of particular
stations in those groups are very different. For example a short playing group uses a lot station cnk19a which
is nearly not used by long playing visitors. Also we can conclude more situations like that also for "middle time" visistors. 

```{r, fig.width=15,  fig.height=15}
table1 = table(as.character(kmFirstGroup$most_freq_station))
table2 = table(as.character(kmSecondGroup$most_freq_station))
table3 = table(as.character(kmThirdGroup$most_freq_station))
table4 = table(as.character(kmFourthGroup$most_freq_station))
table = c(table1, table2, table3, table4)

resultTab <- matrix(table, ncol=4, nrow = length(table1), byrow = TRUE)
rownames(resultTab) <- names(table1)
colnames(resultTab) <- c("1", "2", "3", "4")
resultTab

par(mar = c(5, 4, 1.5, 0.5), ps = 12, cex  = 1, cex.main = 2, las = 1)
barplot(
  resultTab, 
  beside      = TRUE, 
  axes        = TRUE,
  axis.lty    = 1, 
  col         = c("cornflowerblue", "grey", "deepskyblue1", "cornsilk3", "darkgoldenrod4", "darkseagreen3", "bisque3", "coral3", "cyan4"),
  panel.first =  abline(
    h    =  seq.int(25, 100, 25), 
    col  =  "grey", 
    lty  =  2
  )
)

legend("topright", 
       legend = names(table1), 
       fill = c("cornflowerblue", "grey", "deepskyblue1", "cornsilk3", "darkgoldenrod4", "darkseagreen3", "bisque3", "coral3", "cyan4"))



```

### Least frequent station

We can find analogous situation if we analyse a station which is least used by clustered groups of visitors.
We can see that distributions of least used station is much different in every group.

```{r, fig.width=15,  fig.height=15}
table1 = table(as.character(kmFirstGroup$least_freq_station))
table2 = table(as.character(kmSecondGroup$least_freq_station))
table3 = table(as.character(kmThirdGroup$least_freq_station))

table4 = table(as.character(kmFourthGroup$least_freq_station))
result <- rep(0, length(table1))
where <- match( names(table4), names(table1) )
result[ where ] <- table4
table4 = result

table = c(table1, table2, table3, table4)

resultTab <- matrix(table, ncol=4, nrow = length(table1))
rownames(resultTab) <- names(table1)
colnames(resultTab) <- c("1", "2", "3", "4")
resultTab

par(mar = c(5, 4, 1.5, 0.5), ps = 12, cex  = 1, cex.main = 2, las = 1)
barplot(
  resultTab, 
  beside      = TRUE, 
  axes        = TRUE,
  axis.lty    = 1, 
  col         = c("cornflowerblue", "grey", "deepskyblue1", "cornsilk3", "darkgoldenrod4", "darkseagreen3", "bisque3", "coral3", "cyan4"),
  panel.first =  abline(
    h    =  seq.int(25, 100, 25), 
    col  =  "grey", 
    lty  =  2
  )
)

legend("topright", 
       legend = names(table1), 
       fill = c("cornflowerblue", "grey", "deepskyblue1", "cornsilk3", "darkgoldenrod4", "darkseagreen3", "bisque3", "coral3", "cyan4"))



```

### Hour

On the other hand all distributions based on hour visitors play are nearly normal (see normal distribution).

```{r, fig.width=15,  fig.height=15}

table3 = table(as.character(kmThirdGroup$hour))

table1 = table(as.character(kmFirstGroup$hour))
result <- rep(0, length(table3))
where <- match( names(table1), names(table3) )
result[ where ] <- table1
table1 = result

table2 = table(as.character(kmSecondGroup$hour))
result <- rep(0, length(table3))
where <- match( names(table2), names(table3) )
result[ where ] <- table2
table2 = result

table4 = table(as.character(kmFourthGroup$hour))
result <- rep(0, length(table3))
where <- match( names(table4), names(table3) )
result[ where ] <- table4
table4 = result

table = c(table1, table2, table3, table4)


resultTab <- matrix(table, ncol=4, nrow = length(table1))
rownames(resultTab) <- names(table3)
colnames(resultTab) <- c("1", "2", "3", "4")
resultTab

par(mar = c(5, 4, 1.5, 0.5), ps = 12, cex  = 1, cex.main = 2, las = 1)
barplot(
  resultTab, 
  beside      = TRUE, 
  axes        = TRUE,
  axis.lty    = 1, 
  col         = c("cornflowerblue", "grey", "deepskyblue1", "cornsilk3", "darkgoldenrod4", "darkseagreen3", "bisque3", "coral3", "cyan4"),
  panel.first =  abline(
    h    =  seq.int(25, 100, 25), 
    col  =  "grey", 
    lty  =  2
  )
)

legend("topright", 
       legend = names(table3), 
       fill = c("cornflowerblue", "grey", "deepskyblue1", "cornsilk3", "darkgoldenrod4", "darkseagreen3", "bisque3", "coral3", "cyan4"))



```

#Finding a pattern of stations visited by user

In order to find some pattern of stations visited by a user, we introduced new features and distance metric:

<ul>
<li>first_station - a station that user begins with</li>
<li>
last_station - a station that user ends with
</li>
<li>
station_path - a concatenated string of stations in order user visited them
</li>
</ul>

Here as a distance metric we have to use some distance between strings, we use restricted Damerau-Levenshtein distance.
 
```{r, cache=TRUE}
patternData <- mergedData[,c("visitor", "station", "time", "count", "min_date")]
patternData = patternData %>%
  arrange(min_date) %>%
  group_by(visitor) %>%
  summarise(total_time=sum(time),
            total_count = sum(count),
            first_station = head(station,1),
            last_station = tail(station,1),
            station_path = paste(station, collapse="_"),
            most_freq_station = head(station[which(count == max(count))],1),
            least_freq_station = head(station[which(count == min(count))],1))
           
sampleData <- patternData[sample(nrow(patternData), 20000),]
sampleData <- sampleData[order(sampleData$visitor),]
rownames(sampleData) <- sampleData$visitor
```
 
```{r, cache=TRUE, echo=FALSE}
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
```

## Clustering on station_path using hierarchical clustering with restricted Damerau-Levenshtein distance

Now we will cluster our data into 3 groups using hierarchical clustering (hclust):

```{r, fig.width=15,  fig.height=15}
d <- stringdistmatrix(sampleData$station_path, sampleData$station_path)
cl <- hclust(as.dist(d))

sampleData$labels = factor(cutree(cl, k=4))
ggplot(sampleData, aes(total_count, total_time, label=most_freq_station, color=labels))+geom_text(size=3)+theme_bw()
ggplot(sampleData, aes(total_count, total_time, color=labels))+geom_point(size=2)+theme_bw()

firstGroup = (sampleData %>% filter(labels == 1))
secondGroup = (sampleData %>% filter(labels == 2))
thirdGroup = (sampleData %>% filter(labels == 3))
fourthGroup = (sampleData %>% filter(labels == 4))
```

That way of clustering provides grouping visitors with similar behaviour together, for example with similar starting and ending station.
However short playing visitors seem to nearly randomly choose their first station which is usually also their last one.

```{r, fig.width=15,  fig.height=15}
q1 <- ggplot(sampleData, aes(total_count, first_station, color=labels))+geom_point(size=2)+theme_bw()
q2 <- ggplot(sampleData, aes(total_count, last_station, color=labels))+geom_point(size=2)+theme_bw()
multiplot(q1, q2, cols=2)
```

## Analysis of clusters

As before we will try to compare distributions of most and least frequent stations in groups described by our clustering.
We will also show total time distribution shown in every group (notice that we are not clustering on total_time this time).

```{r, fig.width=15,  fig.height=15, warning=FALSE}
q1 <- qplot(firstGroup$total_time)+geom_histogram(bins = 15) 
q2 <- qplot(secondGroup$total_time)+geom_histogram(bins = 15) 
q3 <- qplot(thirdGroup$total_time)+geom_histogram(bins = 15) 
q4 <- qplot(fourthGroup$total_time)+geom_histogram(bins = 15) 
multiplot(q1, q2, q3, q4, cols=2)
```

What we can see here that clustering divided our visitors to groups containing players with different characteristics
of time spend on stations. As before we can see a group of players playing long (more than 500) and shortly (less than 500).
We see that all people with very short total time are clustered to one group. This can mean that we clustered together people
who used our stations "accidentaly" or "sporadically". This is the kind of visitors which comes, play in one or to machines and go "home".
Next we will analize that data from most frequently used station point of view:

```{r, cache=TRUE, fig.height=15, fig.width=15, warning=FALSE}
q1 <- qplot(firstGroup$most_freq_station)+geom_bar() 
q2 <- qplot(secondGroup$most_freq_station)+geom_bar() 
q3 <- qplot(thirdGroup$most_freq_station)+geom_bar() 
q4 <- qplot(fourthGroup$most_freq_station)+geom_bar() 
multiplot(q1, q2, q3, q4, cols=2)
```

From the distributions of stations usage by groups of visitors we can see that a group of short players behaves much different
than a group of long players which can be considered as common/constant visitors (we can consider them as experianced visitors).
Short players use mostly cnk19a which is nearly never used by "long players". However the more visitor play the more often he chooses
cnk05 and cnk56 stations instead of cnk19a, cnk20 or cnk10.

```{r, warning=FALSE}
head(firstGroup[,c("station_path")])
head(secondGroup[,c("station_path")]) 
head(thirdGroup[,c("station_path")])
head(fourthGroup[,c("station_path")])
```

"First middle-time group" users use machines in random way. They start mostly on machines: '20', '05', '10' and ends on '56' or '38'. Also they use machines '66', '61', '18', '20' in random order. In "Second middle-time group" station 'cnk18' is almost not used by group members. On the other hand cnk38 is used very often. Those people uses also cnk66 and cnk05. 
In "Group of long players" visitors starts mostly on 'cnk10' or 'cnk05' machine and then they play on 'cnk66', 'cnk20', 'cnk18' and 'cnk61' machines.
At the end they finish on 'cnk56 and 'cnk38'.

#Summary

We distinguished following similarity measures:
<ol><li>Time dependent features
   <ul><li> total_time - total time spent by visitor on all stations </li>
   <li> max_time - maximal time spent by visitor on one station </li>
   <li> min_time - minimal time spent by visitor on one station </li>
   <li> weekday - a day of a week</li>
   <li> hour - an hour user started using stations </li>
   <li> min_date - an hour with minutes as numeric type of entering first station by visitor </li>
   <li> max_date - an hour with minutes as numeric type of leaving last station by visitor </li> 
   </ul></li>
 <li>station dependent features </li>
 <ul>
   <li> most_freq_station - a station with most interactions with that visitor </li>
   <li> least_freq_station - a station with least interactions with that visitor </li>
   <li> min_count - a minimal number of iteration with a station </li>
   <li> max_count - a maximal number of iteration with a station </li>
   <li> total_count - a total number of iterations with all stations made by the visitor </li>
</ul>
</li>
</ol>

The population is heterogeneous. Research carried out on the supplied data set showed that it is possible to distinguish four groups that show signs of similarities.
<ol>
<li>Group 1 - <i>?Occassional? Short time players</i></li>
<ul><li>Team members uses machines for short time and total numer of used machines is relatively low. Those are people who visited examined stations ?sporadically? ? only one or two Times. This group use mostly ?cnk19a?, which is nearly never used by ?long players?.
Histogram from the document shows that machines, which were used by people, who plays only few times are not used by team members, which uses machine very frequently.
</li></ul>
<li>Group 2 - <i>First middle-time group</i></li>
<ul><li>Group members sses machines more randomly. It is possible to define a path: they start mostly on machine ?cnk19a?, ?cnk05?, ?cnk10? and ends on ?cnk56? or ?cnk38?. To be more precise, they plays also on ?cnk66?, ?cnk61?, ?cnk18?, ?cnk20? - these are chosen in random order. </li></ul>
<li>Group 3 - <i>Second middle-time group</i>
<ul>
<li>Use machines are in more random order. The station ?cnk18? is rarely used by members from the other groups. On the other hand the ?chk38? is used the most often choosen machine. Taking into consideration given results, one can conclude, that ?cnk66? and ?cnk05? are used relatively often.  </li>
</ul>
<li>Group 4 - <i>Long players</i></li>
<ul>
<li>Members of this group develop some schemas and strategies (using specific machines, specific 'paths through machines'). Such members can be considered as 'Addicts'.
From the distributions of stations usage by groups of visitors we can see that a group of short players behaves much different
than a group of long players which can be considered as common/constant visitors (we can consider them as experienced visitors).Machines which are used most frequent: 10, 05, 56, 66.There exists a path, which can be derived from results. In ?Group of longs players? visitors starts mostly on ?cnk10? or ?cnk05? then they switch to ?cnk66?, ?cnk20?, ?cnk18? and ?cnk61? machines. They finish on ?cnk56? and ?cnk38.?
</li>
</ol>

Machine patterns: If we increase the number of classes, we will obtain 100 groups of people with very similar preferences, eg. single person whose behaviour is similar every time. In this way people are clustered together when: they have the same length of their path, visit similar machines and start from the same station.
