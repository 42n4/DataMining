---
title: "Project 2 - Phase 3"
author: "Karolina Kwasiborska, Karol Dzitkowski, Marcel Szczêsny"
date: "2015-01-20"
output: 
   html_document:
     self_contained: yes
     toc: TRUE
---
#Introdution
Copernicus Science Center is a museum which purpose is to promote and popularize science. Visitors can learn about the laws of nature by playing with interactive machines. In order to improve the visitor's experience we analyzed their interaction with machines and found categories of visitors which are characterized by similar factors.

In the first phase we made exploratory analysis and characterized types of interactions with different machines. We tried to answer questions such as:
<ul><li>What is the average time of interaction with a given machine?</li>
<li>Is there a relation between the duraion of an interaction and variables like weekday or hour?</li>
</ul>

In the second phase we segmented visitors into groups. We tried to answer following questions:
<ul><li>How to define the similarity measure between visitors?
is the population homogenous or heterogonous. If heterogeneous then how many groups you can define?</li>
<li>How to characterize different groups of visitors?</li>
<li>Is there a pattern in stations that visitor tends to visit?</li>
</ul>

```{r, echo=FALSE, warning=FALSE, results="hide", message=FALSE}
library(tidyr)
library(caret)
library(dplyr)
library(lubridate)
library(reshape)
library(ggplot2)
library(MASS)
library(cluster)
library(pvclust)
library(dendextend)
library(ape)
library(RColorBrewer)
library(scales)
library(colorspace) # get nice colors
library(plotly)
library(stringdist)
```
```{r, cache=TRUE, echo=FALSE, warning=FALSE, results="hide", message=FALSE}
load("C:\\Users\\Karola\\Documents\\BISD\\Semestr 2\\Data Mining\\Projekt 2\\verySmallLogs.rda")
data <- verySmallLogs %>% 
  mutate(station,
         visitor,
         type,
         date,
         weekday = wday(date, label=TRUE, abbr=FALSE),
         hour = substr(date, 12, 13))

data$date <- as.POSIXct(data$date,format="%Y-%m-%d %H:%M:%S")
data = data[data$visitor != -1,]

dataEntering <- data[data$type=="Entering" & data$visitor != -1,]
dataLeaving <- data[data$type=="Leaving" & data$visitor != -1,]

newdataEntering = dataEntering %>%
group_by(visitor, station) %>%
summarise(min_date=min(date),
          weekday=head(weekday,1),
          hour=head(hour,1),
          count = n())

newdataLeaving = dataLeaving %>%
group_by(visitor, station) %>%
summarise(max_date=max(date),
          weekday=head(weekday,1),
          hour=head(hour,1),
          count = n())

mergedData <- merge(newdataEntering, newdataLeaving, by=c("visitor", "station"))
mergedData$time = as.numeric(mergedData$max_date-mergedData$min_date)
mergedData$weekday = mergedData$weekday.x
mergedData$hour = mergedData$hour.x
mergedData$count = mergedData$count.x
```

## Interactions with different machines
Characterize types of interactions with different machines (exploratory analysis). Try to answer following questions:
<ul><li>What is the average (or distribution) time of interaction with a given machine</li>
<li>Is there a difference in the time of interaction and weekday or hour?</li>

```{r, cache=TRUE, echo=FALSE, warning=FALSE, message=FALSE}
library(ggplot2)
ggplot(data=mergedData,aes(x=time))+geom_bar(binwidth=1)+xlim(0,800)

mergedData = mergedData[mergedData$time < 1000,]
```
From the graph we can see that the most of interactions with machines took less then 200ms. There are a lot of outliers which can be eliminated using threshold "time < 400". Moreover we will use median instead of mean to decrease impact of boundary values on results.

### What is the average time of interaction with a given machine
First we found average duration of visitors' activities and the number of visitors in every station.
```{r, cache=TRUE, fig.width=20,  fig.height=10, echo=FALSE, warning=FALSE, message=FALSE}
avgData = mergedData %>%
group_by(station) %>%
summarise(avgTime = median(time),
          visitorCount = n())
avgData

par(mar=c(2,1.8,2,0))
barplot(c(avgData$visitorCount), main="The Number of visitors in each station", xlab="Stations", ylab = "Number of visitors", names.arg=as.character(avgData$station))

# Distribution of the number of visitors per station
summary(avgData$visitorCount)

par(mar=c(2,1.8,2,0))
barplot(c(avgData$avgTime), main="Average distribution times in each station", xlab="Stations", ylab = "Time[s]",names.arg=as.character(avgData$station))

# Distribution of time per station
summary(avgData$avgTime)


```

The station in which visitors spent definitely the most time is cnk38, therefore the least number of visitors played with it. With cnk19a visitors spent the least time per visit so the biggest amount of visitors had chance to play with it.

###Is there a relation between the duration of an interaction and variables like weekday or hour? 
Then we check if there is a dependence between the duration of an interaction and weekday and hour.

#### Weekday
```{r, cache=TRUE, fig.width=15,  fig.height=10, echo=FALSE, warning=FALSE, message=FALSE}
weekdayStationData = mergedData %>%
group_by(station, weekday) %>%
summarise(avgTime = median(time),
          visitorCount = n())
weekdayStationData = as.data.frame(weekdayStationData)

# Average time spent per station per day

stationDayTimeTab = cast(weekdayStationData, station ~ weekday, value="avgTime")
stationDayTimeTab

par(mar = c(5, 4, 1.5, 0.5), ps = 12, cex  = 1, cex.main = 2, las = 1)
barplot(
  t(as.matrix(stationDayTimeTab)), 
  beside      = TRUE, 
  ylim        = c(0,200),
  xlab        = "Stations",
  ylab        = "Time[s]",
  axes        = TRUE,
  axis.lty    = 1, 
  col         = c("darkblue", "dodgerblue3", "deepskyblue1", "blue", "green", "red", "yellow"),
  panel.first =  abline(
    h    =  seq.int(25, 100, 25), 
    col  =  "grey", 
    lty  =  2
  )
)

legend("topright", 
       legend = c("Sunday",  "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"), 
       fill = c("darkblue", "dodgerblue3", "deepskyblue1", "blue", "green", "red", "yellow"))

# The number of visitors per station per day

stationDayVisitorCountTab = cast(weekdayStationData, station ~ weekday, value="visitorCount")
stationDayVisitorCountTab

par(mar = c(5, 4, 1.5, 0.5), ps = 12, cex  = 1, cex.main = 2, las = 1)
barplot(
  t(as.matrix(stationDayVisitorCountTab)), 
  beside      = TRUE, 
  xlab        = "Stations", 
  ylab        = "Number of visitor",
  axes        = TRUE,
  axis.lty    = 1, 
  col         = c("darkblue", "dodgerblue3", "deepskyblue1", "blue", "green", "red", "yellow"),
  panel.first =  abline(
    h    =  seq.int(25, 100, 25), 
    col  =  "grey", 
    lty  =  2
  )
)

legend("topright", 
       legend = c("Sunday",  "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"), 
       fill = c("darkblue", "dodgerblue3", "deepskyblue1", "blue", "green", "red", "yellow"))



weekdayGeneralData = mergedData %>%
group_by(weekday) %>%
summarise(avgTime = median(time),
          visitorCount = n())
weekdayGeneralData
par(mar=c(2,1.8,2,0))

# Barplot of the number of visitors per weekday
barplot(c(weekdayGeneralData$visitorCount), main="The number of visitors in every weekday", xlab="Weekdays", ylab = "Number of visitors",names.arg=as.character(weekdayGeneralData$weekday))

# Distribution of the number of visitors per weekday
summary(weekdayGeneralData$visitorCount)

# Barplot of time per weekday
barplot(c(weekdayGeneralData$avgTime), main="Average distribution times in every weekday", xlab="Weekdays",ylab = "Time[s]", names.arg=as.character(weekdayGeneralData$weekday))

# Distribution of time per weekday
summary(weekdayGeneralData$avgTime)


```

The average time spent in the stations and the number of visitors during different days of the week were quite similar. The only exception is Monday. Probably during Mondays stations are closed and the only activity with them is maintenance which takes more time than average visitor's activity.

#### Hour
```{r, cache=TRUE, fig.width=15,  fig.height=10, echo=FALSE, warning=FALSE}
hourStationData = mergedData %>%
group_by(station, hour) %>%
summarise(avgTime = median(time),
          visitorCount = n())
hourStationData = as.data.frame(hourStationData)

# Average time spent per station per hour

stationHourTimeTab = cast(hourStationData, station ~ hour, value="avgTime")
stationHourTimeTab

par(mar = c(5, 4, 1.5, 0.5), ps = 12, cex  = 1, cex.main = 2, las = 1)
barplot(
  t(as.matrix(stationHourTimeTab)), 
  beside      = TRUE, 
  ylim        = c(0,200),
  xlab        = "Stations",
  ylab        = "Time[s]",
  axes        = TRUE,
  axis.lty    = 1, 
  col         = c("darkblue", "dodgerblue3", "deepskyblue1", "blue", "green", "red", "yellow", "cornflowerblue", "grey",  "cornsilk3", "darkgoldenrod4", "darkseagreen3", "bisque3", "coral3", "cyan4"),
  panel.first =  abline(
    h    =  seq.int(25, 100, 25), 
    col  =  "grey", 
    lty  =  2
  )
)

legend("topright", 
       legend = c("7", "8", "9", "10", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20", "21"), 
       fill = c("darkblue", "dodgerblue3", "deepskyblue1", "blue", "green", "red", "yellow", "cornflowerblue", "grey",  "cornsilk3", "darkgoldenrod4", "darkseagreen3", "bisque3", "coral3", "cyan4"))

# The number of visitors per station per hour

stationHourVisitorCountTab = cast(hourStationData, station ~ hour, value="visitorCount")
stationHourVisitorCountTab

par(mar = c(5, 4, 1.5, 0.5), ps = 12, cex  = 1, cex.main = 2, las = 1)
barplot(
  t(as.matrix(stationHourVisitorCountTab)), 
  beside      = TRUE, 
  xlab        = "Stations",
  ylab        = "Number of visitors",
  axes        = TRUE,
  axis.lty    = 1, 
  col         = c("darkblue", "dodgerblue3", "deepskyblue1", "blue", "green", "red", "yellow", "cornflowerblue", "grey",  "cornsilk3", "darkgoldenrod4", "darkseagreen3", "bisque3", "coral3", "cyan4"),
  panel.first =  abline(
    h    =  seq.int(25, 100, 25), 
    col  =  "grey", 
    lty  =  2
  )
)

legend("topright", 
       legend = c("7", "8", "9", "10", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20", "21"), 
       fill = c("darkblue", "dodgerblue3", "deepskyblue1", "blue", "green", "red", "yellow", "cornflowerblue", "grey",  "cornsilk3", "darkgoldenrod4", "darkseagreen3", "bisque3", "coral3", "cyan4"))

hourGeneralData = mergedData %>%
group_by(hour) %>%
summarise(avgTime = median(time),
          visitorCount = n())
hourGeneralData

# The number of visitors every hour
barplot(c(hourGeneralData$visitorCount), main="The number of visitors every hour", xlab="Hours",ylab = "Number of visitors",  names.arg=hourGeneralData$hour)

# Distribution of the number of visitors per weekday
summary(hourGeneralData$visitorCount)

# Average times in every hour
barplot(c(hourGeneralData$avgTime), main="Average times in every hour", xlab="Hours",ylab = "Time[s]", names.arg=hourGeneralData$hour)

# Distribution of time per weekday
summary(hourGeneralData$avgTime)

```

The greatest number of visitors came in the middle of the day (between 12 AM and 4 PM)
In the evening (7PM - 9PM) and in the morning (7AM - 9AM) the activity of visitors was the smallest. Between 9PM and 7AM there was no interaction with stations at all.

In average the time spent in the stations was the highest at 7AM. In the morning spent time was the lowest. During the day differences weren't very big.

#### Weekday and hour
```{r, cache=TRUE, fig.width=15,  fig.height=10, echo=FALSE, warning=FALSE}
stationData = mergedData %>%
group_by(station, weekday, hour) %>%
summarise(avgTime = median(time),
          visitorCount = n())
#stationData

# Distribution of time per station, weekday and hour
summary(stationData$avgTime)

# Distribution of the number of visitors per station, weekday and hour
summary(stationData$visitorCount)

generalData = mergedData %>%
group_by(weekday, hour) %>%
summarise(avgTime = median(time),
          visitorCount = n())
generalData = as.data.frame(generalData)

generalVisitorCountTab = cast(generalData, weekday ~ hour, value="visitorCount")
generalVisitorCountTab

par(mar = c(5, 4, 1.5, 0.5), ps = 12, cex  = 1, cex.main = 2, las = 1)
barplot(
  t(as.matrix(generalVisitorCountTab)), 
  beside      = TRUE, 
  xlab        = "Weekday",
  ylab        = "Number of visitors",
  axes        = TRUE,
  axis.lty    = 1, 
  col         = c("darkblue", "dodgerblue3", "deepskyblue1", "blue", "green", "red", "yellow", "cornflowerblue", "grey",  "cornsilk3", "darkgoldenrod4", "darkseagreen3", "bisque3", "coral3", "cyan4"),
  panel.first =  abline(
    h    =  seq.int(25, 100, 25), 
    col  =  "grey", 
    lty  =  2
  )
)

legend("topright", 
       legend = c("7", "8", "9", "10", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20", "21"), 
       fill = c("darkblue", "dodgerblue3", "deepskyblue1", "blue", "green", "red", "yellow", "cornflowerblue", "grey",  "cornsilk3", "darkgoldenrod4", "darkseagreen3", "bisque3", "coral3", "cyan4"))

generalTimeTab = cast(generalData, weekday ~ hour, value="avgTime")
generalTimeTab

par(mar = c(5, 4, 1.5, 0.5), ps = 12, cex  = 1, cex.main = 2, las = 1)
barplot(
  t(as.matrix(generalTimeTab)), 
  beside      = TRUE, 
  xlab        = "Weekday",
  ylab        = "Time[s]",
  axes        = TRUE,
  axis.lty    = 1, 
  col         = c("darkblue", "dodgerblue3", "deepskyblue1", "blue", "green", "red", "yellow", "cornflowerblue", "grey",  "cornsilk3", "darkgoldenrod4", "darkseagreen3", "bisque3", "coral3", "cyan4"),
  panel.first =  abline(
    h    =  seq.int(25, 100, 25), 
    col  =  "grey", 
    lty  =  2
  )
)

legend("topright", 
       legend = c("7", "8", "9", "10", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20", "21"), 
       fill = c("darkblue", "dodgerblue3", "deepskyblue1", "blue", "green", "red", "yellow", "cornflowerblue", "grey",  "cornsilk3", "darkgoldenrod4", "darkseagreen3", "bisque3", "coral3", "cyan4"))

```

## Visitors segmentation
In the second phase try to segment visitors into separate categories / segments. Try to answer following questions:
<ul>
<li>
How to define the similarity measure between visitors?
<li>
Is the population homogenous or heterogonous. If heterogeneous then how many groups you can derive/define?
<li>
How to characterize different groups of visitors?
Is there a pattern in stations that visitor tends to visit?

### Introducing new features
Try to get data by visitor (not by visitor, station) and introduce new features that we tried to use in our clustering

<ol><li>Time dependent features
   <ul><li> total_time - total time spent by visitor on all stations </li>
   <li> max_time - maximal time spent by visitor on one station </li>
   <li> min_time - minimal time spent by visitor on one station </li>
   <li> weekday - a day of a week</li>
   <li> hour - an hour user started using stations </li>
   <li> min_date - an hour with minutes as numeric type of entering first station by visitor </li>
   <li> max_date - an hour with minutes as numeric type of leaving last station by visitor </li> 
   </ul></li>
 <li>station dependent features </li>
 <ul>
   <li> most_freq_station - a station with most interactions with that visitor </li>
   <li> least_freq_station - a station with least interactions with that visitor </li>
   <li> min_count - a minimal number of iteration with a station </li>
   <li> max_count - a maximal number of iteration with a station </li>
   <li> total_count - a total number of iterations with all stations made by the visitor </li>
</ul>
</li>
</ol>

As a distance metric we will use deafault distance between vectors used by kmeans, of selected features from those above.
To cluster our data in this part we will use kmeans algorithm.

```{r, cache=TRUE, message=FALSE, results="hide", echo=FALSE}
phase1Data <- mergedData[,c("visitor", "station", "max_date", "min_date", "time", "weekday", "hour", "count")]

phase1Data = phase1Data %>%
  group_by(visitor) %>%
  summarise(max_date=max(max_date),
            min_date=min(min_date),
            total_time=sum(time),
            min_time=min(time),
            max_time=max(time),
            weekday=head(weekday,1),
            hour=head(hour,1),
            total_count = sum(count),
            max_count = max(count),
            min_count = min(count),
            most_freq_station = head(station[which(count == max(count))],1),
            least_freq_station = head(station[which(count == min(count))],1))

sampleData <- phase1Data
```
```{r, cache=TRUE, message=FALSE, results="hide", echo=FALSE}

kmeansData <- transform(sampleData, 
                        visitor = as.numeric(visitor),
                        max_date = as.POSIXlt(max_date)$hour + as.POSIXlt(max_date)$min/60,
                        min_date = as.POSIXlt(min_date)$hour + as.POSIXlt(min_date)$min/60,
                        total_time = as.numeric(total_time),
                        min_time = as.numeric(min_time),
                        max_time = as.numeric(max_time),
                        hour = as.numeric(hour),
                        label = visitor)
```
```{r, cache=TRUE, message=FALSE, results="hide", echo=FALSE}
 kmeansData$max_date <- scale(kmeansData$max_date)
 kmeansData$min_date <- scale(kmeansData$min_date)
 kmeansData$total_time <- scale(kmeansData$total_time)
 kmeansData$min_time <- scale(kmeansData$min_time)
 kmeansData$max_time <- scale(kmeansData$max_time)
 kmeansData$total_count <- scale(kmeansData$total_count)
 kmeansData$max_count <- scale(kmeansData$max_count)
 kmeansData$min_count <- scale(kmeansData$min_count)
```

###Use K-means on features: total_time, total_count
Firstly we tried to analyse visitors clustered by total_time and total_count features, splitting them to
groups of visitors how play long and do many iterations and those to play shorter and do less interactions.
In order to do that we cluster in 4 groups and analyze what stations people in every group mostly use.

```{r, message=FALSE, echo=FALSE}
set.seed(4)
model1 <- kmeans(kmeansData[,c("total_time", "total_count")], 4)
kmeansData$cluster <- factor(model1$cluster)
nd <- data.frame(model1$centers)

ggplot(kmeansData, aes(total_time, total_count)) +
  geom_text(size=3, aes(label=most_freq_station, color=cluster)) + 
  geom_point(data=nd, size=3)+
  theme_bw()

kmFirstGroup = kmeansData[kmeansData$cluster == 1,]
kmSecondGroup = kmeansData[kmeansData$cluster == 2,]
kmThirdGroup = kmeansData[kmeansData$cluster == 3,]
kmFourthGroup = kmeansData[kmeansData$cluster == 4,]
```

#### Most frequent station
Analysis of most_frequent station with data clustered in 4 groups, we can see here that usage of particular
stations in those groups are very different. For example a short playing group uses a lot station cnk19a which
is nearly not used by long playing visitors. Also we can conclude more situations like that also for "middle time" visistors. 

```{r, fig.width=15,  fig.height=15, message=FALSE, echo=FALSE}
table1 = table(as.character(kmFirstGroup$most_freq_station))
table2 = table(as.character(kmSecondGroup$most_freq_station))
table3 = table(as.character(kmThirdGroup$most_freq_station))
table4 = table(as.character(kmFourthGroup$most_freq_station))
table = c(table1, table2, table3, table4)

resultTab <- matrix(table, ncol=4, nrow = length(table1), byrow = TRUE)
rownames(resultTab) <- names(table1)
colnames(resultTab) <- c("1", "2", "3", "4")
resultTab

par(mar = c(5, 4, 1.5, 0.5), ps = 12, cex  = 1, cex.main = 2, las = 1)
barplot(
  resultTab, 
  beside      = TRUE, 
  axes        = TRUE,
  axis.lty    = 1, 
  col         = c("cornflowerblue", "grey", "deepskyblue1", "cornsilk3", "darkgoldenrod4", "darkseagreen3", "bisque3", "coral3", "cyan4"),
  panel.first =  abline(
    h    =  seq.int(25, 100, 25), 
    col  =  "grey", 
    lty  =  2
  )
)

legend("topright", 
       legend = names(table1), 
       fill = c("cornflowerblue", "grey", "deepskyblue1", "cornsilk3", "darkgoldenrod4", "darkseagreen3", "bisque3", "coral3", "cyan4"))



```

#### Least frequent station
We can find analogous situation if we analyse a station which is least used by clustered groups of visitors.
We can see that distributions of least used station is much different in every group.

```{r, fig.width=15,  fig.height=15, warning = FALSE, message = FALSE, echo=FALSE}
table1 = table(as.character(kmFirstGroup$least_freq_station))
table2 = table(as.character(kmSecondGroup$least_freq_station))
table3 = table(as.character(kmThirdGroup$least_freq_station))

table4 = table(as.character(kmFourthGroup$least_freq_station))
result <- rep(0, length(table1))
where <- match( names(table4), names(table1) )
result[ where ] <- table4
table4 = result

table = c(table1, table2, table3, table4)

resultTab <- matrix(table, ncol=4, nrow = length(table1))
rownames(resultTab) <- names(table1)
colnames(resultTab) <- c("1", "2", "3", "4")
resultTab

par(mar = c(5, 4, 1.5, 0.5), ps = 12, cex  = 1, cex.main = 2, las = 1)
barplot(
  resultTab, 
  beside      = TRUE, 
  axes        = TRUE,
  axis.lty    = 1, 
  col         = c("cornflowerblue", "grey", "deepskyblue1", "cornsilk3", "darkgoldenrod4", "darkseagreen3", "bisque3", "coral3", "cyan4"),
  panel.first =  abline(
    h    =  seq.int(25, 100, 25), 
    col  =  "grey", 
    lty  =  2
  )
)

legend("topright", 
       legend = names(table1), 
       fill = c("cornflowerblue", "grey", "deepskyblue1", "cornsilk3", "darkgoldenrod4", "darkseagreen3", "bisque3", "coral3", "cyan4"))



```

#### Hour

On the other hand all distributions based on hour visitors play are nearly normal (see normal distribution).

```{r, fig.width=15,  fig.height=15, message=FALSE}
hours = unique(c(as.character(kmFirstGroup$hour), as.character(kmSecondGroup$hour), as.character(kmThirdGroup$hour), as.character(kmFourthGroup$hour)))
hours = sort.int(hours)

table1 = table(as.character(kmFirstGroup$hour))
result <- rep(0, length(hours))
where <- match( names(table1), hours )
where = where[!is.na(where)]
result[ where ] <- table1
table1 = result

table2 = table(as.character(kmSecondGroup$hour))
result <- rep(0, length(hours))
where <- match( names(table2), hours )
where = where[!is.na(where)]
result[ where ] <- table2
table2 = result

table3 = table(as.character(kmThirdGroup$hour))
result <- rep(0, length(hours))
where <- match( names(table3),hours)
where = where[!is.na(where)]
result[ where ] <- table3
table3 = result

table4 = table(as.character(kmFourthGroup$hour))
result <- rep(0, length(hours))
where <- match( names(table4), hours)
where = where[!is.na(where)]
result[ where ] <- table4
table4 = result

table = c(table1, table2, table3, table4)


resultTab <- matrix(table, ncol=4, nrow = length(hours))
rownames(resultTab) <- hours
colnames(resultTab) <- c("1", "2", "3", "4")
resultTab

par(mar = c(5, 4, 1.5, 0.5), ps = 12, cex  = 1, cex.main = 2, las = 1)
barplot(
  resultTab, 
  beside      = TRUE, 
  axes        = TRUE,
  axis.lty    = 1, 
  col         = c("darkblue", "dodgerblue3", "deepskyblue1", "blue", "green", "red", "yellow", "cornflowerblue", "grey",  "cornsilk3", "darkgoldenrod4", "darkseagreen3", "bisque3", "coral3", "cyan4"),
  panel.first =  abline(
    h    =  seq.int(25, 100, 25), 
    col  =  "grey", 
    lty  =  2
  )
)

legend("topright", 
       legend = hours, 
       fill = c("darkblue", "dodgerblue3", "deepskyblue1", "blue", "green", "red", "yellow", "cornflowerblue", "grey",  "cornsilk3", "darkgoldenrod4", "darkseagreen3", "bisque3", "coral3", "cyan4"))

```

###Finding a pattern of stations visited by user

In order to find some pattern of stations visited by a user, we introduced new features and distance metric:

<ul>
<li>first_station - a station that user begins with</li>
<li>
last_station - a station that user ends with
</li>
<li>
station_path - a concatenated string of stations in order user visited them
</li>
</ul>

Here as a distance metric we have to use some distance between strings, we use restricted Damerau-Levenshtein distance.
 
```{r, cache=TRUE, message=FALSE, results="hide", echo=FALSE}
patternData <- mergedData[,c("visitor", "station", "time", "count", "min_date")]
patternData = patternData %>%
  arrange(min_date) %>%
  group_by(visitor) %>%
  summarise(total_time=sum(time),
            total_count = sum(count),
            first_station = head(station,1),
            last_station = tail(station,1),
            station_path = paste(station, collapse="_"),
            most_freq_station = head(station[which(count == max(count))],1),
            least_freq_station = head(station[which(count == min(count))],1))
           
sampleData <- patternData[sample(nrow(patternData), 2000),]
sampleData <- sampleData[order(sampleData$visitor),]
rownames(sampleData) <- sampleData$visitor
```
 
```{r, cache=TRUE, echo=FALSE, message=FALSE, echo=FALSE}
library(grid)
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
```

#### Clustering on station_path using hierarchical clustering with restricted Damerau-Levenshtein distance

Now we will cluster our data into 3 groups using hierarchical clustering (hclust):

```{r, fig.width=15,  fig.height=15, message=FALSE, echo=FALSE}
d <- stringdistmatrix(sampleData$station_path, sampleData$station_path)
cl <- hclust(as.dist(d))

sampleData$labels = factor(cutree(cl, k=4))
ggplot(sampleData, aes(total_count, total_time, label=most_freq_station, color=labels))+geom_text(size=3)+theme_bw()
ggplot(sampleData, aes(total_count, total_time, color=labels))+geom_point(size=2)+theme_bw()

firstGroup = (sampleData %>% filter(labels == 1))
secondGroup = (sampleData %>% filter(labels == 2))
thirdGroup = (sampleData %>% filter(labels == 3))
fourthGroup = (sampleData %>% filter(labels == 4))
```

That way of clustering provides grouping visitors with similar behaviour together, for example with similar starting and ending station.
However short playing visitors seem to nearly randomly choose their first station which is usually also their last one.

```{r, fig.width=15,  fig.height=15, message=FALSE, echo=FALSE}
q1 <- ggplot(sampleData, aes(total_count, first_station, color=labels))+geom_point(size=2)+theme_bw()
q2 <- ggplot(sampleData, aes(total_count, last_station, color=labels))+geom_point(size=2)+theme_bw()
multiplot(q1, q2, cols=2)
```

#### Analysis of clusters

As before we will try to compare distributions of most and least frequent stations in groups described by our clustering.
We will also show total time distribution shown in every group (notice that we are not clustering on total_time this time).

```{r, fig.width=15,  fig.height=15, warning=FALSE, echo=FALSE, message=FALSE}
q1 <- qplot(firstGroup$total_time)+geom_histogram(bins = 15) 
q2 <- qplot(secondGroup$total_time)+geom_histogram(bins = 15) 
q3 <- qplot(thirdGroup$total_time)+geom_histogram(bins = 15) 
q4 <- qplot(fourthGroup$total_time)+geom_histogram(bins = 15) 
multiplot(q1, q2, q3, q4, cols=2)
```

What we can see here that clustering divided our visitors to groups containing players with different characteristics
of time spend on stations. As before we can see a group of players playing long (more than 500) and shortly (less than 500).
We see that all people with very short total time are clustered to one group. This can mean that we clustered together people
who used our stations "accidentaly" or "sporadically". This is the kind of visitors which comes, play in one or to machines and go "home".
Next we will analize that data from most frequently used station point of view:

```{r, cache=TRUE, fig.height=15, fig.width=15, warning=FALSE, echo=FALSE, message=FALSE}
q1 <- qplot(firstGroup$most_freq_station)+geom_bar() 
q2 <- qplot(secondGroup$most_freq_station)+geom_bar() 
q3 <- qplot(thirdGroup$most_freq_station)+geom_bar() 
q4 <- qplot(fourthGroup$most_freq_station)+geom_bar() 
multiplot(q1, q2, q3, q4, cols=2)
```

From the distributions of stations usage by groups of visitors we can see that a group of short players behaves much different
than a group of long players which can be considered as common/constant visitors (we can consider them as experianced visitors).
Short players use mostly cnk19a which is nearly never used by "long players". However the more visitor play the more often he chooses
cnk05 and cnk56 stations instead of cnk19a, cnk20 or cnk10.

```{r, warning=FALSE, echo=FALSE, cache=TRUE, message=FALSE}
head(firstGroup[,c("station_path")])
head(secondGroup[,c("station_path")]) 
head(thirdGroup[,c("station_path")])
head(fourthGroup[,c("station_path")])
```
"First middle-time group" users use machines in random way. They start mostly on machines: 'cnk05', 'cnk10' and ends on 'cnk56' or 'cnk61'. Also they use machines 'cnk66', 'cnk18' in random order. 
In "Second middle-time group" station 'cnk18' is almost not used by group members. On the other hand cnk05 and 'cnk66' are used very often. Those people uses also 'cnk10', 'cnk38' and 'cnk56'. 
In "Group of long players" visitors starts mostly on 'cnk10' or 'cnk05' machine and then they play on 'cnk66', 'cnk20', 'cnk18' and 'cnk61' machines.
At the end they finish mostly on 'cnk38'.

```{r, warning=FALSE, echo=FALSE, cache=TRUE, message=FALSE}
results = list()
results2 = list()
no_clusters <- 1:50
for(i in no_clusters)
{
  groups<-cutree(cl, k=i)
  x<-cbind(sampleData, groups)
  val <- 0
  val2 <- 0
  for(j in 1:i)
  {
    y <- subset(x, groups==j)
    n <- nrow(y)
    s <- sum(sum(stringdistmatrix(y$station_path, y$station_path)))
    val <- val + s
    val2 <- val2 + (s/n)
  }
  results[i] <- val
  results2[i] <- val2
}
distance_sum <- unlist(results)
distance_mean <- unlist(results2)
```

```{r, cache=TRUE, fig.height=15, fig.width=15, warning=FALSE, echo=FALSE, message=FALSE}
plot(no_clusters, distance_sum, type='l', lwd=2, col='red')
plot(no_clusters, distance_mean, type='l', lwd=2, col='red')
```

We can see that optimal number of clusters is 4-5 since there we have the most gain in mean distance reduction in clusters. For more than 5 clusters this "error" is changing very slowly. Also we can conclude that our data is heterogenous, since we have big drop in error at the beginning and then it flattens. If data were homogenous we would have uniform and steady slope.

# Summary
Interactions with different machines:

Taking into consideration all results, we conclude, that average time spent by each visitor on each station was different. The most popular machine was cnk38: visitors spent the most time with it, therefore small number of visitors had chance to play with it. The conclusion is that the owner of stations should buy new cnk38 machines.
 
Furthermore computation shows, that during various hours the number of visitors was different. Between 1PM and 4PM the activity of visitors was the greatest. The owner of the stations can provide more machines in the middle of the day so the biggest number of visitors will be able to play with them.
 
Moreover at different days times spent with machines where quite similar, therefore there is no need to plan any changes.

Visitors segmentation:

We distinguished following similarity measures:
<ol><li>Time dependent features
   <ul><li> total_time - total time spent by visitor on all stations </li>
   <li> max_time - maximal time spent by visitor on one station </li>
   <li> min_time - minimal time spent by visitor on one station </li>
   <li> weekday - a day of a week</li>
   <li> hour - an hour user started using stations </li>
   <li> min_date - an hour with minutes as numeric type of entering first station by visitor </li>
   <li> max_date - an hour with minutes as numeric type of leaving last station by visitor </li>
   </ul></li>
 <li>station dependent features </li>
 <ul>
   <li> most_freq_station - a station with most interactions with that visitor </li>
   <li> least_freq_station - a station with least interactions with that visitor </li>
   <li> min_count - a minimal number of iteration with a station </li>
   <li> max_count - a maximal number of iteration with a station </li>
   <li> total_count - a total number of iterations with all stations made by the visitor </li>
</ul>
</li>
</ol>
 
The population is heterogeneous. Research carried out on the supplied data set showed that it is possible to distinguish four groups that show signs of similarities.
<ol>
<li>Group 1 - <i>Occassional short time players</i></li>
<ul><li>Team members uses machines for short time and total numer of used machines is relatively low. Those are people who visited examined stations sporadically  only one or two times. This group use mostly cnk19a, which is nearly never used by long players.
Histogram from the document shows that machines, which were used by people, who plays only few times are not used by team members, which uses machine very frequently.
</li></ul>
<li>Group 2 - <i>First middle-time group</i></li>
<ul><li>Group members uses machines more randomly. It is possible to define a path: they start mostly on machine 'cnk19a', 'cnk05, cnk10 and ends on cnk56 or cnk38. To be more precise, they plays also on cnk66, cnk61, cnk18, cnk20 - these are chosen in random order.
This group uses 'cnk05' the most frequently.</li></ul>
<li>Group 3 - <i>Second middle-time group</i>
<ul>
<li>Use machines are in more random order. Moreover the cnk05 and 'cnk66' are the most often choosen machine. Taking into consideration given results, one can conclude, that cnk10 and cnk38 and 'cnk56' are used relatively often.  </li>
</ul>
<li>Group 4 - <i>Long players</i></li>
<ul>
<li>Members of this group develop some schemas and strategies (using specific machines, specific 'paths through machines'). Such members can be considered as 'Addicts'.
From the distributions of stations usage by groups of visitors we can see that a group of short players behaves much different
than a group of long players which can be considered as common/constant visitors (we can consider them as experienced visitors).Machines which are used most frequent: 'cnk10', 'cnk05', 'cnk56', 'cnk66' .There exists a path, which can be derived from results. In Group of longs players visitors starts mostly on cnk10 or cnk05 then they switch to cnk66, cnk20, cnk18 and cnk61 machines. They finish on usually on cnk38' and 'cnk56'.
</li>
</ol>
 
## Conclusions
After analysis we end up with some conclusions and we are able to provide some suggestions for management of the centre.
Firstly, we found specific machines for which time of interaction with user is long (example: 'cnk38'). Our idea is to increase number of such machines.
Moreover, it will be a good concept to extend an exhibit with a machines, which concerns similar topic of science.
Among the machines, which user interaction time is long, there are also machines which are rarely used. It means that visitors probably does not know how to use and enjoy playing with the machine. As a result they are discouraged.
Our suggestion is to provide detailed instruction - user manual or ensure user's guide for center's employee. This will result in increased interest of such machines.


Segmentation of visitors allowed us to find 4 groups of visitors who have similar characteristics.

The first group are those who use small amount of machines, rather short and choose the stations randomly. Such people probably feel a little bit lost in the centre and do not know where to start. For those visitors the tours should be organized that will introduce to the most important matters of science. The guides should show the most interesting machines and encourage further exploration of science.

The second distinct group are visitors who spend a lot of time with machines and visit a lot of them. Taking into account that they often follow similar paths and watch similar machines, we can conclude that they visit the centre again and know which machines are most interesting. Moreover they are interested in science and eager to return to the centre. A good idea is to try to encourage them to watch the machines they visit rarely. To do this, you can arrange tours of the rarely visited machines. 
For this group of people guides can also organize special thematic meetings, during which visitors will gain more knowledge about topics of science that they are most interested in.

Middle-time players who (like short-time players) visits machines randomly can attend tours about basic topics of science to find some interesting subjects for them.
